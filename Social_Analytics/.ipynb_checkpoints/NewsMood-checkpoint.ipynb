{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Mood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first plot will be and/or feature the following:\n",
    "\n",
    "\n",
    "Be a scatter plot of sentiments of the last 100 tweets sent out by each news organization, ranging from -1.0 to 1.0, where a score of 0 expresses a neutral sentiment, -1 the most negative sentiment possible, and +1 the most positive sentiment possible.\n",
    "Each plot point will reflect the compound sentiment of a tweet.\n",
    "Sort each plot point by its relative timestamp.\n",
    "\n",
    "\n",
    "The second plot will be a bar plot visualizing the overall sentiments of the last 100 tweets from each organization. For this plot, you will again aggregate the compound sentiments analyzed by VADER.\n",
    "\n",
    "The tools of the trade you will need for your task as a data analyst include the following: tweepy, pandas, matplotlib, and VADER.\n",
    "\n",
    "Your final Jupyter notebook must:\n",
    "\n",
    "\n",
    "Pull last 100 tweets from each outlet.\n",
    "Perform a sentiment analysis with the compound, positive, neutral, and negative scoring for each tweet.\n",
    "Pull into a DataFrame the tweet's source account, its text, its date, and its compound, positive, neutral, and negative sentiment scores.\n",
    "Export the data in the DataFrame into a CSV file.\n",
    "Save PNG images for each plot.\n",
    "\n",
    "\n",
    "As final considerations:\n",
    "\n",
    "\n",
    "You must complete your analysis using a Jupyter notebook.\n",
    "You must use the Matplotlib or Pandas plotting libraries.\n",
    "Include a written description of three observable trends based on the data.\n",
    "Include proper labeling of your plots, including plot titles (with date of analysis) and axes labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import tweepy\n",
    "import time\n",
    "#import Twitter_API_Keys\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and Initialize Sentiment Analyzer\n",
    "#from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter API Keys\n",
    "consumer_key = \"r88UzgUheSOF3pMyINIT5yITY\"\n",
    "consumer_secret = \"kq3NV0k5Dlq4uCucw5Nf0sJAuP09l0Xja1pNc1DenZoxWSKwxk\"\n",
    "access_token = \"421125873-OuCvIPTHHMqC9t8uG8CTSBLi7iK4NNEyZeDQMc9w\"\n",
    "access_token_secret = \"EC2ookZjWBWKo5MpCoEEtrg2OGiF8WZZ1LCiv4nxl45tH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n",
    "\n",
    "# Select News Sources (Twitter Accounts)\n",
    "news_source = [\"FoxNews\",\"CNN\",\"BBCWorld\",\"CBSNews\",\"nytimes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Search Term\n",
    "target_terms = (\"@BBC\",\"@CBSNews\",\"@CNN\",\"@FoxNews\", \"@nytimes\")\n",
    "\n",
    "# \"Real Person\" Filters\n",
    "min_tweets = 5\n",
    "max_tweets = 10000\n",
    "max_followers = 2500\n",
    "max_following = 2500\n",
    "lang = \"en\"\n",
    "\n",
    "# Array to hold sentiment\n",
    "sentiment_array = []\n",
    "\n",
    "# Variable for holding the oldest tweet\n",
    "oldest_tweet = \"\"\n",
    "\n",
    "# Loop through all target users\n",
    "for target in target_terms:\n",
    "\n",
    "    # Variables for holding sentiments\n",
    "    compound_list = []\n",
    "    positive_list = []\n",
    "    negative_list = []\n",
    "    neutral_list = []\n",
    "\n",
    "    # Loop through 10 times (total of 1000 tweets)\n",
    "    for x in range(10):\n",
    "\n",
    "        # Run search around each tweet\n",
    "        public_tweets = api.search(target, count=100, result_type=\"recent\")\n",
    "\n",
    "        # Loop through all tweets\n",
    "        for tweet in public_tweets[\"statuses\"]:\n",
    "\n",
    "            # Use filters to check if user meets conditions\n",
    "            if (tweet[\"user\"][\"followers_count\"] < max_followers and\n",
    "                tweet[\"user\"][\"statuses_count\"] > min_tweets and\n",
    "                tweet[\"user\"][\"statuses_count\"] < max_tweets and\n",
    "                tweet[\"user\"][\"friends_count\"] < max_following and\n",
    "                    tweet[\"user\"][\"lang\"] == lang):\n",
    "\n",
    "                # Run Vader Analysis on each tweet\n",
    "                compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "                pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "                neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "                neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "\n",
    "                # Add each value to the appropriate array\n",
    "                compound_list.append(compound)\n",
    "                positive_list.append(pos)\n",
    "                negative_list.append(neg)\n",
    "                neutral_list.append(neu)\n",
    "\n",
    "    # Store the Average Sentiments\n",
    "    sentiment = {\"User\": target,\n",
    "                 \"Date\": tweet[\"created_at\"],\n",
    "                 \"Compound\": [np.mean(compound_list)],\n",
    "                 \"Positive\": np.mean(positive_list),\n",
    "                 \"Neutral\": np.mean(negative_list),\n",
    "                 \"Negative\": np.mean(neutral_list),\n",
    "                 \"Tweet Count\": len(compound_list)}\n",
    "\n",
    "    # Print the Sentiments\n",
    "    print(sentiment)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData=3.6]",
   "language": "python",
   "name": "conda-env-PythonData=3.6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
